init_config:

instances:
  - host: {{ .Env.DATABASE_HOST }}
    port: 5432
    username: datadog
    password: {{ .Env.DATABASE_PASSWORD }}
    dbname: app
#    ssl: False
#    tags:
#      - optional_tag1
#      - optional_tag2

#    Collect metrics regarding PL/pgSQL functions from pg_stat_user_functions
    collect_function_metrics: True

#    Collect count metrics, default value is True for backward compatibility but they might be slow,
#    suggested value is False.
    collect_count_metrics: True

#    Collect metrics regarding transactions from pg_stat_activity, default value is False. Please make sure the user
#    has sufficient privileges to read from pg_stat_activity before enabling this option.
    collect_activity_metrics: True

#    Collect database size metrics. Default value is True but they might be slow with large databases
    collect_database_size_metrics: True

#    Include statistics from the default database 'postgres' in the check metrics, default to false
    collect_default_database: True

## log Section (Available for Agent >=6.0)
#logs:

    # - type : (mandatory) type of log input source (tcp / udp / file)
    #   port / path : (mandatory) Set port if type is tcp or udp. Set path if type is file
    #   service : (mandatory) name of the service owning the log
    #   source : (mandatory) attribute that defines which integration is sending the logs
    #   sourcecategory : (optional) Multiple value attribute. Can be used to refine the source attribute
    #   tags: (optional) add tags to each logs collected

#  - type: file
#    path: /path/to/postgres.log
#    source: postgresql
#    sourcecategory: database
#    service: myapp
#    #To handle multi line that starts with yyyy-mm-dd or yyyy-dd-mm use the following pattern
#    log_processing_rules:
#      - type: multi_line
#        pattern: \d{4}\-(0?[1-9]|1[012])\-(0?[1-9]|[12][0-9]|3[01])
#        name: new_log_start_with_date
